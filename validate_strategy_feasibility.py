"""
ç­–ç•¥å¯è¡Œæ€§ç»¼åˆéªŒè¯
éªŒè¯æ–‡æ¡£ä¸­çš„1165%æ”¶ç›Šæ˜¯å¦çœŸå®å¯ä¿¡

æ£€æŸ¥é¡¹ï¼š
1. æ˜¯å¦å­˜åœ¨æ—¶é—´æ³„éœ²ï¼ˆä½¿ç”¨æœªæ¥æ•°æ®ï¼‰
2. æ˜¯å¦å­˜åœ¨ç”Ÿå­˜åå·®
3. å›æµ‹é€»è¾‘æ˜¯å¦æ­£ç¡®
4. åŸºå‡†æ•°æ®æ˜¯å¦å‡†ç¡®
5. æ ·æœ¬å¤–æµ‹è¯•è¡¨ç°
6. äº¤æ˜“æˆæœ¬å½±å“
"""
import os
import pandas as pd
import numpy as np
from config import config
from scipy import stats

DATA_DIR = os.path.join(config.BASE_DIR, "data_for_opt_stocks")
PRICES_FILE = os.path.join(DATA_DIR, "prices.csv")

START_DATE = '2021-12-03'
END_DATE = '2026-01-23'
WEIGHTS = {2: 0.3, 20: 0.7}
TOP_N = 4
HOLD_DAYS = 3

def check_lookahead_bias():
    """æ£€æŸ¥1: æ—¶é—´æ³„éœ²æ£€æŸ¥"""
    print("\n" + "="*60)
    print("âœ“ æ£€æŸ¥1: æ—¶é—´æ³„éœ²æ£€æŸ¥")
    print("="*60)

    # è¯»å–ä¸€æ®µæ•°æ®æ£€æŸ¥é€»è¾‘
    stocks = pd.read_csv(PRICES_FILE, index_col=0, parse_dates=True)
    stocks = stocks.loc[START_DATE:END_DATE]

    # æ¨¡æ‹Ÿåœ¨æŸä¸€å¤©çš„è®¡ç®—
    test_date = stocks.index[100]  # éšæœºé€‰ä¸€å¤©
    hist = stocks[stocks.index <= test_date]

    # æ£€æŸ¥è®¡ç®—2æ—¥å’Œ20æ—¥æ”¶ç›Šæ˜¯å¦ä½¿ç”¨äº†æœªæ¥æ•°æ®
    for p in [2, 20]:
        ret_correct = hist.iloc[-1] / hist.iloc[-(p+1)] - 1
        ret_wrong = hist.iloc[-1] / hist.iloc[-1-p] - 1  # é”™è¯¯æ–¹å¼

        print(f"\nPeriod {p}å¤©:")
        print(f"  æ­£ç¡®æ–¹æ³• (ä½¿ç”¨Tå’ŒT-{p}): {ret_correct.head(3).to_dict()}")
        print(f"  é”™è¯¯æ–¹æ³• (ä¼šæ³„éœ²): {ret_wrong.head(3).to_dict()}")

        # éªŒè¯ä»£ç ä¸­ä½¿ç”¨çš„æ˜¯æ­£ç¡®æ–¹æ³•
        # verify_final_backtest.py line 58: ret = stocks / stocks.shift(p) - 1
        ret_code = stocks.loc[:test_date].iloc[-1] / stocks.loc[:test_date].shift(p).iloc[-1] - 1
        assert ret_code.equals(ret_correct), f"ä»£ç é€»è¾‘ä¸æ­£ç¡®æ–¹æ³•ä¸ä¸€è‡´ï¼"

    print("\nâœ… é€šè¿‡: ä»£ç ä½¿ç”¨æ­£ç¡®çš„æ—¶é—´é€»è¾‘ï¼Œæ— æœªæ¥æ•°æ®æ³„éœ²")
    return True

def check_survivorship_bias():
    """æ£€æŸ¥2: ç”Ÿå­˜åå·®æ£€æŸ¥"""
    print("\n" + "="*60)
    print("âœ“ æ£€æŸ¥2: ç”Ÿå­˜åå·®æ£€æŸ¥")
    print("="*60)

    stocks = pd.read_csv(PRICES_FILE, index_col=0, parse_dates=True)
    stocks = stocks.loc[START_DATE:END_DATE]

    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    n_stocks = len(stocks.columns)
    n_days = len(stocks)

    # è®¡ç®—æ¯åªè‚¡ç¥¨çš„ç¼ºå¤±ç‡
    missing_pct = stocks.isna().sum() / len(stocks)

    # ç»Ÿè®¡é€€å¸‚/åœç‰Œè‚¡ç¥¨
    delisted = missing_pct[missing_pct > 0.5]  # è¶…è¿‡50%ç¼ºå¤±

    print(f"\næ€»è‚¡ç¥¨æ•°: {n_stocks}")
    print(f"äº¤æ˜“æ—¥æ•°: {n_days}")
    print(f"ä¸¥é‡ç¼ºå¤±è‚¡ç¥¨ (>50%): {len(delisted)}")
    print(f"ç¼ºå¤±ç‡åˆ†å¸ƒ: min={missing_pct.min():.2%}, median={missing_pct.median():.2%}, max={missing_pct.max():.2%}")

    if len(delisted) > 0:
        print(f"\nâš ï¸ è­¦å‘Š: å­˜åœ¨{len(delisted)}åªä¸¥é‡ç¼ºå¤±æ•°æ®çš„è‚¡ç¥¨")
        print("å¯èƒ½å­˜åœ¨ç”Ÿå­˜åå·® - å›æµ‹ä¸­æ’é™¤äº†é€€å¸‚è‚¡ç¥¨")
        return False
    else:
        print("\nâœ… é€šè¿‡: æ•°æ®é›†è¾ƒå®Œæ•´")
        return True

def check_backtest_logic():
    """æ£€æŸ¥3: å›æµ‹é€»è¾‘éªŒè¯"""
    print("\n" + "="*60)
    print("âœ“ æ£€æŸ¥3: å›æµ‹é€»è¾‘éªŒè¯")
    print("="*60)

    stocks = pd.read_csv(PRICES_FILE, index_col=0, parse_dates=True)
    stocks = stocks.loc[START_DATE:END_DATE]

    # è®¡ç®—åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    score_df = pd.DataFrame(0.0, index=stocks.index, columns=stocks.columns)
    for p, w in WEIGHTS.items():
        ret = stocks / stocks.shift(p) - 1
        rank = ret.rank(axis=1, pct=True).fillna(0.5)
        score_df += rank * w

    # æ£€æŸ¥åˆ†æ•°åˆ†å¸ƒ
    print(f"\nåˆ†æ•°ç»Ÿè®¡:")
    print(f"  å‡å€¼: {score_df.mean().mean():.4f}")
    print(f"  æ ‡å‡†å·®: {score_df.std().mean():.4f}")
    print(f"  èŒƒå›´: [{score_df.min().min():.4f}, {score_df.max().max():.4f}]")

    # æ£€æŸ¥é€‰è‚¡é€»è¾‘
    # é€‰å‡ºä¸€å¤©çš„Top 4
    test_day = score_df.iloc[100]
    top_stocks = test_day.nlargest(TOP_N)
    print(f"\næµ‹è¯•æ—¥æœŸ {score_df.index[100].date()} é€‰å‡ºçš„è‚¡ç¥¨:")
    for stock, score in top_stocks.items():
        print(f"  {stock}: {score:.4f}")

    # éªŒè¯åˆ†ä»“é€»è¾‘
    top_n_mask = pd.DataFrame(False, index=score_df.index, columns=score_df.columns)
    vals = score_df.values
    vals = np.nan_to_num(vals, nan=-np.inf)
    idx = np.argpartition(-vals, TOP_N, axis=1)[:, :TOP_N]
    rows = np.arange(len(score_df))[:, None]
    top_n_mask.values[rows, idx] = True

    # æ£€æŸ¥æ¯å¤©æ˜¯å¦é€‰äº†TOP_Nä¸ªè‚¡ç¥¨
    daily_count = top_n_mask.sum(axis=1)
    assert (daily_count == TOP_N).all(), f"é€‰è‚¡æ•°é‡ä¸ä¸€è‡´: {daily_count.unique()}"

    print(f"\nâœ… é€šè¿‡: æ¯å¤©éƒ½æ­£ç¡®é€‰å‡º{TOP_N}åªè‚¡ç¥¨")
    return True

def check_out_of_sample():
    """æ£€æŸ¥4: æ ·æœ¬å¤–æµ‹è¯•"""
    print("\n" + "="*60)
    print("âœ“ æ£€æŸ¥4: æ ·æœ¬å¤–æµ‹è¯• (æ—¶é—´åˆ†å‰²)")
    print("="*60)

    stocks = pd.read_csv(PRICES_FILE, index_col=0, parse_dates=True)
    stocks = stocks.loc[START_DATE:END_DATE]

    # åˆ†å‰²ä¸ºè®­ç»ƒæœŸå’Œæµ‹è¯•æœŸ (70/30)
    split_idx = int(len(stocks) * 0.7)
    train_period = stocks.iloc[:split_idx]
    test_period = stocks.iloc[split_idx:]

    print(f"\nè®­ç»ƒæœŸ: {train_period.index[0].date()} åˆ° {train_period.index[-1].date()} ({len(train_period)}å¤©)")
    print(f"æµ‹è¯•æœŸ: {test_period.index[0].date()} åˆ° {test_period.index[-1].date()} ({len(test_period)}å¤©)")

    # åœ¨ä¸¤ä¸ªæœŸé—´åˆ†åˆ«å›æµ‹
    results = {}
    for name, data in [("è®­ç»ƒæœŸ", train_period), ("æµ‹è¯•æœŸ", test_period)]:
        score_df = pd.DataFrame(0.0, index=data.index, columns=data.columns)
        for p, w in WEIGHTS.items():
            ret = data / data.shift(p) - 1
            rank = ret.rank(axis=1, pct=True).fillna(0.5)
            score_df += rank * w

        # ç®€åŒ–å›æµ‹ï¼šæ¯å¤©ä¹°top Nï¼ŒæŒæœ‰1å¤©
        top_n_mask = pd.DataFrame(False, index=score_df.index, columns=score_df.columns)
        vals = score_df.values
        vals = np.nan_to_num(vals, nan=-np.inf)
        idx = np.argpartition(-vals, TOP_N, axis=1)[:, :TOP_N]
        rows = np.arange(len(score_df))[:, None]
        top_n_mask.values[rows, idx] = True

        market_ret = data.pct_change().fillna(0.0)
        port_ret = (market_ret * top_n_mask.shift(1)).sum(axis=1) / TOP_N
        port_ret = port_ret.iloc[1:]  # å»æ‰ç¬¬ä¸€å¤©

        cum_ret = (1 + port_ret).cumprod().iloc[-1] - 1
        results[name] = cum_ret

        print(f"\n{name}æ”¶ç›Š: {cum_ret:.2%}")

    # æ¯”è¾ƒè®­ç»ƒæœŸå’Œæµ‹è¯•æœŸ
    if results["æµ‹è¯•æœŸ"] > 0.5 * results["è®­ç»ƒæœŸ"]:
        print(f"\nâœ… é€šè¿‡: æµ‹è¯•æœŸè¡¨ç°ç¨³å®š (æµ‹è¯•æœŸæ”¶ç›Šä¸ºè®­ç»ƒæœŸçš„{results['æµ‹è¯•æœŸ']/results['è®­ç»ƒæœŸ']:.1%})")
        return True
    else:
        print(f"\nâš ï¸ è­¦å‘Š: æµ‹è¯•æœŸè¡¨ç°å¤§å¹…è¡°å‡ (ä»…ä¸ºè®­ç»ƒæœŸçš„{results['æµ‹è¯•æœŸ']/results['è®­ç»ƒæœŸ']:.1%})")
        return False

def check_transaction_costs():
    """æ£€æŸ¥5: äº¤æ˜“æˆæœ¬å½±å“"""
    print("\n" + "="*60)
    print("âœ“ æ£€æŸ¥5: äº¤æ˜“æˆæœ¬æ•æ„Ÿæ€§åˆ†æ")
    print("="*60)

    stocks = pd.read_csv(PRICES_FILE, index_col=0, parse_dates=True)
    stocks = stocks.loc[START_DATE:END_DATE]

    # ç®€åŒ–å›æµ‹
    score_df = pd.DataFrame(0.0, index=stocks.index, columns=stocks.columns)
    for p, w in WEIGHTS.items():
        ret = stocks / stocks.shift(p) - 1
        rank = ret.rank(axis=1, pct=True).fillna(0.5)
        score_df += rank * w

    top_n_mask = pd.DataFrame(False, index=score_df.index, columns=score_df.columns)
    vals = score_df.values
    vals = np.nan_to_num(vals, nan=-np.inf)
    idx = np.argpartition(-vals, TOP_N, axis=1)[:, :TOP_N]
    rows = np.arange(len(score_df))[:, None]
    top_n_mask.values[rows, idx] = True

    # è®¡ç®—æ¢æ‰‹ç‡
    turnover_daily = (top_n_mask != top_n_mask.shift(1)).sum(axis=1) / (2 * TOP_N)
    avg_turnover = turnover_daily.mean()

    print(f"\nå¹³å‡å•å‘æ¢æ‰‹ç‡: {avg_turnover:.2%} /å¤©")
    print(f"æŒ‰3å¤©æ¢ä»“ä¼°ç®—: {avg_turnover * 3:.2%} /3å¤©")

    # ä¸åŒäº¤æ˜“æˆæœ¬ä¸‹çš„æ”¶ç›Š
    market_ret = stocks.pct_change().fillna(0.0)

    # æ»šåŠ¨3åˆ†ä»“
    port_daily = pd.Series(0.0, index=stocks.index)
    for lag in range(1, HOLD_DAYS + 1):
        m = top_n_mask.shift(lag).fillna(False)
        tranche_ret = (market_ret * m).sum(axis=1) / TOP_N
        port_daily += tranche_ret
    port_daily /= HOLD_DAYS
    port_daily = port_daily.iloc[HOLD_DAYS:]

    # è®¡ç®—å®é™…æ¢ä»“æ¬¡æ•°ï¼ˆæ¯3å¤©ï¼‰
    trades_per_year = 252 / HOLD_DAYS

    print(f"\nä¸åŒäº¤æ˜“æˆæœ¬ä¸‹çš„å¹´åŒ–æ”¶ç›Š:")
    base_cum = (1 + port_daily).cumprod().iloc[-1] - 1
    n_days = len(port_daily)
    base_ann = (1 + base_cum) ** (252 / n_days) - 1

    for cost_bps in [0, 10, 20, 30, 50]:
        # æ¯æ¬¡æ¢ä»“æˆæœ¬ = å•å‘æ¢æ‰‹ç‡ * æˆæœ¬
        # 3å¤©æ¢ä»“ï¼Œå¹³å‡æ¢æ‰‹ç‡ = avg_turnover * 3
        annual_cost = (avg_turnover * 3) * (cost_bps / 10000) * trades_per_year
        net_ann = base_ann - annual_cost

        print(f"  {cost_bps}bps: {net_ann:.2%} (æŸè€—: {annual_cost:.2%}/å¹´)")

    if base_ann - 0.005 * trades_per_year > 0.5 * base_ann:
        print(f"\nâœ… é€šè¿‡: å³ä½¿50bpsæˆæœ¬ï¼Œç­–ç•¥ä»æœ‰æ˜¾è‘—è¶…é¢")
        return True
    else:
        print(f"\nâš ï¸ è­¦å‘Š: äº¤æ˜“æˆæœ¬ä¼šå¤§å¹…ä¾µèš€æ”¶ç›Š")
        return False

def check_benchmark_accuracy():
    """æ£€æŸ¥6: åŸºå‡†æ•°æ®å‡†ç¡®æ€§"""
    print("\n" + "="*60)
    print("âœ“ æ£€æŸ¥6: åŸºå‡†æ•°æ®éªŒè¯")
    print("="*60)

    from gm.api import set_token, history, ADJUST_PREV
    set_token(config.GM_TOKEN)

    try:
        # è·å–åˆ›ä¸šæ¿ETFæ•°æ®
        print("\næ­£åœ¨è·å–åˆ›ä¸šæ¿ETF (159915) æ•°æ®...")
        df = history(symbol='SZSE.159915', frequency='1d',
                    start_time=START_DATE, end_time=END_DATE,
                    fields='close,eob', adjust=ADJUST_PREV, df=True)

        if df.empty:
            print("âŒ æ— æ³•è·å–åŸºå‡†æ•°æ®")
            return False

        df['eob'] = pd.to_datetime(df['eob']).dt.tz_localize(None)
        bench = df.set_index('eob')['close']

        # è®¡ç®—æ”¶ç›Š
        start_price = bench.iloc[0]
        end_price = bench.iloc[-1]
        total_ret = (end_price / start_price - 1)

        print(f"\nåˆ›ä¸šæ¿ETFä»·æ ¼:")
        print(f"  èµ·å§‹ ({bench.index[0].date()}): {start_price:.4f}")
        print(f"  ç»“æŸ ({bench.index[-1].date()}): {end_price:.4f}")
        print(f"  æ€»æ”¶ç›Š: {total_ret:.2%}")

        # æ£€æŸ¥æ˜¯å¦åˆç†
        if abs(total_ret) > 1.0:  # è¶…è¿‡100%æ¶¨è·Œ
            print(f"\nâš ï¸ è­¦å‘Š: åŸºå‡†æ”¶ç›Šç‡{total_ret:.2%}å¼‚å¸¸ï¼Œå¯èƒ½æ•°æ®æœ‰è¯¯")
            return False

        # å¯¹æ¯”åˆ›ä¸šæ¿æŒ‡æ•°
        print("\næ­£åœ¨è·å–åˆ›ä¸šæ¿æŒ‡æ•° (399006) æ•°æ®...")
        df2 = history(symbol='SZSE.399006', frequency='1d',
                     start_time=START_DATE, end_time=END_DATE,
                     fields='close,eob', df=True)

        if not df2.empty:
            df2['eob'] = pd.to_datetime(df2['eob']).dt.tz_localize(None)
            idx = df2.set_index('eob')['close']
            idx_ret = (idx.iloc[-1] / idx.iloc[0] - 1)
            print(f"  åˆ›ä¸šæ¿æŒ‡æ•°æ”¶ç›Š: {idx_ret:.2%}")
            print(f"  ETF vs æŒ‡æ•°å·®å¼‚: {abs(total_ret - idx_ret):.2%}")

        print(f"\nâœ… åŸºå‡†æ•°æ®å·²éªŒè¯")
        return True

    except Exception as e:
        print(f"\nâŒ åŸºå‡†æ•°æ®è·å–å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰éªŒè¯"""
    print("\n" + "="*60)
    print("ğŸ” ç­–ç•¥å¯è¡Œæ€§ç»¼åˆéªŒè¯")
    print("="*60)
    print(f"ç­–ç•¥: Day 2 (30%) + Day 20 (70%)")
    print(f"æœŸé—´: {START_DATE} åˆ° {END_DATE}")
    print(f"æŒä»“: Top {TOP_N} è‚¡ç¥¨, æ¯{HOLD_DAYS}å¤©æ¢ä»“")

    if not os.path.exists(PRICES_FILE):
        print(f"\nâŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {PRICES_FILE}")
        return

    results = {}

    # è¿è¡Œå„é¡¹æ£€æŸ¥
    checks = [
        ("æ—¶é—´æ³„éœ²", check_lookahead_bias),
        ("ç”Ÿå­˜åå·®", check_survivorship_bias),
        ("å›æµ‹é€»è¾‘", check_backtest_logic),
        ("æ ·æœ¬å¤–æµ‹è¯•", check_out_of_sample),
        ("äº¤æ˜“æˆæœ¬", check_transaction_costs),
        ("åŸºå‡†æ•°æ®", check_benchmark_accuracy),
    ]

    for name, func in checks:
        try:
            results[name] = func()
        except Exception as e:
            print(f"\nâŒ {name}æ£€æŸ¥å¤±è´¥: {e}")
            results[name] = False

    # æ€»ç»“
    print("\n\n" + "="*60)
    print("ğŸ“‹ éªŒè¯ç»“æœæ€»ç»“")
    print("="*60)

    for name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{status}: {name}")

    passed_count = sum(results.values())
    total_count = len(results)

    print("\n" + "="*60)
    if passed_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç­–ç•¥å¯è¡Œæ€§è¾ƒé«˜")
        print("\nâš ï¸ ä½†ä»éœ€æ³¨æ„:")
        print("  1. å¾®ç›˜è‚¡æµåŠ¨æ€§é£é™© - å¤§èµ„é‡‘å¯èƒ½æ— æ³•å¤åˆ¶")
        print("  2. æœ€å¤§å›æ’¤-67% - éœ€è¦æå¼ºçš„é£é™©æ‰¿å—èƒ½åŠ›")
        print("  3. è¿‡å»è¡¨ç°ä¸ä»£è¡¨æœªæ¥ - éœ€æŒç»­ç›‘æ§")
    elif passed_count >= total_count * 0.7:
        print(f"âš ï¸ éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ ({passed_count}/{total_count})")
        print("ç­–ç•¥æœ‰ä¸€å®šå¯è¡Œæ€§ï¼Œä½†å­˜åœ¨é£é™©")
    else:
        print(f"âŒ å¤šé¡¹æ£€æŸ¥å¤±è´¥ ({passed_count}/{total_count})")
        print("ç­–ç•¥å¯è¡Œæ€§å­˜ç–‘ï¼Œå»ºè®®è°¨æ…å¯¹å¾…")
    print("="*60)

if __name__ == "__main__":
    main()
